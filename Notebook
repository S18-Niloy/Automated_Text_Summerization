{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2734496,"sourceType":"datasetVersion","datasetId":1654566}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom transformers import BertTokenizer, EncoderDecoderModel, Trainer, TrainingArguments, DataCollatorForSeq2Seq\nfrom datasets import Dataset, load_metric\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-08-30T19:54:07.662385Z","iopub.execute_input":"2024-08-30T19:54:07.662843Z","iopub.status.idle":"2024-08-30T19:54:07.675516Z","shell.execute_reply.started":"2024-08-30T19:54:07.662800Z","shell.execute_reply":"2024-08-30T19:54:07.674429Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# Load datasets\ntrain_df = pd.read_csv('/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv')\nval_df = pd.read_csv('/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/validation.csv')\ntest_df = pd.read_csv('/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv')\n\n# Display some sample data\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-30T19:54:10.430092Z","iopub.execute_input":"2024-08-30T19:54:10.430885Z","iopub.status.idle":"2024-08-30T19:54:29.585041Z","shell.execute_reply.started":"2024-08-30T19:54:10.430822Z","shell.execute_reply":"2024-08-30T19:54:29.583681Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"                                         id  \\\n0  0001d1afc246a7964130f43ae940af6bc6c57f01   \n1  0002095e55fcbd3a2f366d9bf92a95433dc305ef   \n2  00027e965c8264c35cc1bc55556db388da82b07f   \n3  0002c17436637c4fe1837c935c04de47adb18e9a   \n4  0003ad6ef0c37534f80b55b4235108024b407f0b   \n\n                                             article  \\\n0  By . Associated Press . PUBLISHED: . 14:11 EST...   \n1  (CNN) -- Ralph Mata was an internal affairs li...   \n2  A drunk driver who killed a young woman in a h...   \n3  (CNN) -- With a breezy sweep of his pen Presid...   \n4  Fleetwood are the only team still to have a 10...   \n\n                                          highlights  \n0  Bishop John Folda, of North Dakota, is taking ...  \n1  Criminal complaint: Cop used his role to help ...  \n2  Craig Eccleston-Todd, 27, had drunk at least t...  \n3  Nina dos Santos says Europe must be ready to a...  \n4  Fleetwood top of League One after 2-0 win at S...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>article</th>\n      <th>highlights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>\n      <td>By . Associated Press . PUBLISHED: . 14:11 EST...</td>\n      <td>Bishop John Folda, of North Dakota, is taking ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>\n      <td>(CNN) -- Ralph Mata was an internal affairs li...</td>\n      <td>Criminal complaint: Cop used his role to help ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00027e965c8264c35cc1bc55556db388da82b07f</td>\n      <td>A drunk driver who killed a young woman in a h...</td>\n      <td>Craig Eccleston-Todd, 27, had drunk at least t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0002c17436637c4fe1837c935c04de47adb18e9a</td>\n      <td>(CNN) -- With a breezy sweep of his pen Presid...</td>\n      <td>Nina dos Santos says Europe must be ready to a...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0003ad6ef0c37534f80b55b4235108024b407f0b</td>\n      <td>Fleetwood are the only team still to have a 10...</td>\n      <td>Fleetwood top of League One after 2-0 win at S...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Preprocessing function\ndef preprocess_data(df):\n    return Dataset.from_pandas(df[['article', 'highlights']])\n\n# Convert DataFrames to Datasets\ntrain_dataset = preprocess_data(train_df)\nvalid_dataset = preprocess_data(val_df)\ntest_dataset = preprocess_data(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T19:54:59.711581Z","iopub.execute_input":"2024-08-30T19:54:59.712497Z","iopub.status.idle":"2024-08-30T19:55:10.998766Z","shell.execute_reply.started":"2024-08-30T19:54:59.712454Z","shell.execute_reply":"2024-08-30T19:55:10.997459Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# Load BERT tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2024-08-30T19:55:21.309653Z","iopub.execute_input":"2024-08-30T19:55:21.310086Z","iopub.status.idle":"2024-08-30T19:55:22.185347Z","shell.execute_reply.started":"2024-08-30T19:55:21.310044Z","shell.execute_reply":"2024-08-30T19:55:22.184283Z"},"trusted":true},"execution_count":59,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e47d60b3b8a24d6db41b40302afa383b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e855b48c5e904724a78974cc2edbe9e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fb5427297bd4fc88dd02be8b2fbc64a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b38fb98a94d5427ea6721be240df0395"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Tokenizer function\ndef tokenize_function(examples):\n    inputs = tokenizer(examples['article'], max_length=512, truncation=True, padding=\"max_length\")\n    outputs = tokenizer(examples['highlights'], max_length=128, truncation=True, padding=\"max_length\")\n    inputs[\"labels\"] = outputs[\"input_ids\"]\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2024-08-30T19:55:29.766158Z","iopub.execute_input":"2024-08-30T19:55:29.766576Z","iopub.status.idle":"2024-08-30T19:55:29.774929Z","shell.execute_reply.started":"2024-08-30T19:55:29.766537Z","shell.execute_reply":"2024-08-30T19:55:29.773375Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# Tokenize the datasets\ntrain_dataset = train_dataset.map(tokenize_function, batched=True)\nvalid_dataset = valid_dataset.map(tokenize_function, batched=True)\ntest_dataset = test_dataset.map(tokenize_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T19:55:44.904699Z","iopub.execute_input":"2024-08-30T19:55:44.905111Z","iopub.status.idle":"2024-08-30T22:51:12.092243Z","shell.execute_reply.started":"2024-08-30T19:55:44.905071Z","shell.execute_reply":"2024-08-30T22:51:12.091002Z"},"trusted":true},"execution_count":61,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/287113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf801576417249d9ba19511345954393"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13368 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80b9b1b85a054972b41d4c1a47e3c12f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/11490 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ba966df37a24b768db9ea8bd6590c22"}},"metadata":{}}]},{"cell_type":"code","source":"# Load pre-trained Encoder-Decoder model\nmodel = EncoderDecoderModel.from_encoder_decoder_pretrained('bert-base-uncased', 't5-small')\n\n# Set decoder start token ID\nmodel.config.decoder_start_token_id = tokenizer.cls_token_id\n\n# Set special tokens\nmodel.config.pad_token_id = tokenizer.pad_token_id\nmodel.config.eos_token_id = tokenizer.sep_token_id\n\n# Set DataCollator\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    num_train_epochs=3,\n    logging_dir='./logs',\n    logging_steps=10,\n    evaluation_strategy='steps',\n    save_steps=500,\n    save_total_limit=2,\n    predict_with_generate=True,\n    fp16=True \n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=valid_dataset,\n    data_collator=data_collator,\n    tokenizer=tokenizer\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\ntrainer.train()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the validation dataset\neval_results = trainer.evaluate()\nprint(f\"Validation Loss: {eval_results['eval_loss']}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test the model on the test dataset\ntest_results = trainer.predict(test_dataset)\ntest_predictions = tokenizer.batch_decode(test_results.predictions, skip_special_tokens=True)\nprint(test_predictions[:5])  # Print the first 5 predictions","metadata":{},"execution_count":null,"outputs":[]}]}