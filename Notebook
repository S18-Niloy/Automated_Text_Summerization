{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2734496,"sourceType":"datasetVersion","datasetId":1654566}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install transformers datasets torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-30T16:08:12.900153Z","iopub.execute_input":"2024-08-30T16:08:12.900563Z","iopub.status.idle":"2024-08-30T16:08:28.939907Z","shell.execute_reply.started":"2024-08-30T16:08:12.900518Z","shell.execute_reply":"2024-08-30T16:08:28.938701Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.21.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset, DatasetDict\n\n# Load datasets\ntrain_df = pd.read_csv(\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv\")\nval_df = pd.read_csv(\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/validation.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv\")\n    \n\n# Convert to Hugging Face datasets\ntrain_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)\ntest_dataset = Dataset.from_pandas(test_df)\n\n# Create a DatasetDict\ndatasets = DatasetDict({\n    'train': train_dataset,\n    'validation': val_dataset,\n    'test': test_dataset\n})\n","metadata":{"execution":{"iopub.status.busy":"2024-08-30T16:08:42.234511Z","iopub.execute_input":"2024-08-30T16:08:42.234991Z","iopub.status.idle":"2024-08-30T16:09:12.503791Z","shell.execute_reply.started":"2024-08-30T16:08:42.234945Z","shell.execute_reply":"2024-08-30T16:09:12.502738Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n\n# Load pre-trained model and tokenizer\nmodel_name = \"t5-small\"\ntokenizer = T5Tokenizer.from_pretrained(model_name)\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)\n\n# Tokenize function\ndef preprocess_function(examples):\n    inputs = examples['article']\n    targets = examples['highlights']\n    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n    \n    # Setup the tokenizer for targets\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(targets, max_length=150, truncation=True)\n    \n    model_inputs['labels'] = labels['input_ids']\n    return model_inputs\n\n# Apply tokenization\ntokenized_datasets = datasets.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T16:09:27.042507Z","iopub.execute_input":"2024-08-30T16:09:27.042887Z","iopub.status.idle":"2024-08-30T17:01:19.775641Z","shell.execute_reply.started":"2024-08-30T16:09:27.042855Z","shell.execute_reply":"2024-08-30T17:01:19.774538Z"},"trusted":true},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/287113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d12dfa139b0b4ced959fd3b92d6d919e"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13368 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfcff33b3646430199383a5d66f7c4bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/11490 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d03ea544c6534ec4930e8c2760e9a978"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import T5ForConditionalGeneration, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n\n# Load model\nmodel = T5ForConditionalGeneration.from_pretrained('t5-small')\n\n# Data collator\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n\n# Training arguments\ntraining_args = TrainingArguments(\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    output_dir='./results',\n    num_train_epochs=3,\n    logging_dir='./logs',\n    logging_steps=10,\n    save_steps=500,\n    evaluation_strategy='steps'\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets['train'],\n    eval_dataset=tokenized_datasets['validation'],\n    tokenizer=tokenizer,\n    data_collator=data_collator\n)\n\n# Train model\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-30T17:10:57.566512Z","iopub.execute_input":"2024-08-30T17:10:57.566929Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='221' max='215337' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   221/215337 47:19 < 774:43:30, 0.08 it/s, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>2.745200</td>\n      <td>2.496920</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>2.568500</td>\n      <td>2.312383</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>2.222000</td>\n      <td>2.227994</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>2.355500</td>\n      <td>2.165904</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>2.438800</td>\n      <td>2.096750</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>2.242700</td>\n      <td>2.042759</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>2.024700</td>\n      <td>2.026695</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>2.301300</td>\n      <td>2.011144</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>2.124800</td>\n      <td>1.999748</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>2.150700</td>\n      <td>1.995977</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>2.342500</td>\n      <td>1.986295</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>2.159300</td>\n      <td>1.976962</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>2.039500</td>\n      <td>1.970832</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>2.370900</td>\n      <td>1.965340</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>2.094300</td>\n      <td>1.958885</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>2.037400</td>\n      <td>1.952232</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>2.079700</td>\n      <td>1.950752</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>2.236400</td>\n      <td>1.947548</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>2.078100</td>\n      <td>1.943968</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>2.247900</td>\n      <td>1.941986</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>2.082100</td>\n      <td>1.942581</td>\n    </tr>\n  </tbody>\n</table><p>\n    <div>\n      \n      <progress value='131' max='3342' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 131/3342 00:05 < 02:08, 24.99 it/s]\n    </div>\n    "},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate model\nresults = trainer.evaluate(tokenized_datasets['test'])\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T15:34:11.397147Z","iopub.execute_input":"2024-08-30T15:34:11.397469Z","iopub.status.idle":"2024-08-30T15:34:19.204122Z","shell.execute_reply.started":"2024-08-30T15:34:11.397437Z","shell.execute_reply":"2024-08-30T15:34:19.202950Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def summarize(text):\n    inputs = tokenizer(text, return_tensors='pt', max_length=512, truncation=True)\n    summary_ids = model.generate(inputs['input_ids'], max_length=150, num_beams=4, early_stopping=True)\n    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\n# Example inference\narticle = \"Your long article text here...\"\nsummary = summarize(article)\nprint(summary)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T15:34:19.217431Z","iopub.execute_input":"2024-08-30T15:34:19.217967Z","iopub.status.idle":"2024-08-30T15:34:19.222575Z","shell.execute_reply.started":"2024-08-30T15:34:19.217919Z","shell.execute_reply":"2024-08-30T15:34:19.221684Z"},"trusted":true},"execution_count":43,"outputs":[]}]}