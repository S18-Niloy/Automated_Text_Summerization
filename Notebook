{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2734496,"sourceType":"datasetVersion","datasetId":1654566}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport nltk\nimport networkx as nx\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nnltk.download('punkt')","metadata":{"execution":{"iopub.status.busy":"2024-09-01T20:17:04.439856Z","iopub.execute_input":"2024-09-01T20:17:04.440168Z","iopub.status.idle":"2024-09-01T20:17:07.577278Z","shell.execute_reply.started":"2024-09-01T20:17:04.440134Z","shell.execute_reply":"2024-09-01T20:17:07.576192Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# Load datasets\ntrain_df = pd.read_csv('/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv')\ntest_df = pd.read_csv('/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv')\nval_df = pd.read_csv('/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/validation.csv')\n\n# Sample article\narticle_text = test_df['article'][0]\n\n# Preprocess the text (tokenization)\nsentences = sent_tokenize(article_text)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T20:17:17.540761Z","iopub.execute_input":"2024-09-01T20:17:17.542050Z","iopub.status.idle":"2024-09-01T20:17:48.657655Z","shell.execute_reply.started":"2024-09-01T20:17:17.541975Z","shell.execute_reply":"2024-09-01T20:17:48.656775Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def sentence_similarity(sent1, sent2):\n    sent1 = [w.lower() for w in word_tokenize(sent1)]\n    sent2 = [w.lower() for w in word_tokenize(sent2)]\n    \n    # Combine the sentences\n    all_words = list(set(sent1 + sent2))\n    \n    # Create vectors\n    vector1 = [0] * len(all_words)\n    vector2 = [0] * len(all_words)\n    \n    # Vector for the first sentence\n    for w in sent1:\n        vector1[all_words.index(w)] += 1\n    \n    # Vector for the second sentence\n    for w in sent2:\n        vector2[all_words.index(w)] += 1\n    \n    # Compute cosine similarity\n    return cosine_similarity([vector1], [vector2])[0][0]\n\ndef build_similarity_matrix(sentences):\n    # Initialize similarity matrix\n    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n    \n    for i in range(len(sentences)):\n        for j in range(len(sentences)):\n            if i != j:\n                similarity_matrix[i][j] = sentence_similarity(sentences[i], sentences[j])\n    \n    return similarity_matrix\n\nsimilarity_matrix = build_similarity_matrix(sentences)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T20:18:20.348976Z","iopub.execute_input":"2024-09-01T20:18:20.349798Z","iopub.status.idle":"2024-09-01T20:18:20.645760Z","shell.execute_reply.started":"2024-09-01T20:18:20.349756Z","shell.execute_reply":"2024-09-01T20:18:20.644827Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Build the similarity graph\nsimilarity_graph = nx.from_numpy_array(similarity_matrix)\n\n# Use PageRank algorithm to rank sentences\nscores = nx.pagerank(similarity_graph)\n\n# Rank sentences based on scores\nranked_sentences = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n\n# Select the top N sentences (e.g., top 5 sentences)\nN = 5\nsummary = \" \".join([ranked_sentences[i][1] for i in range(N)])\n\nprint(\"Summary:\")\nprint(summary)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T20:18:25.883975Z","iopub.execute_input":"2024-09-01T20:18:25.884384Z","iopub.status.idle":"2024-09-01T20:18:25.902502Z","shell.execute_reply.started":"2024-09-01T20:18:25.884347Z","shell.execute_reply":"2024-09-01T20:18:25.901495Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Summary:\nBut these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the Detroit News. Tests conducted by the FAA use planes with a 31 inch pitch, a standard which on some airlines has decreased . This week, a U.S consumer advisory group set up by the Department of Transportation said at a public hearing that while the government is happy to set standards for animals flying on planes, it doesn't stipulate a minimum amount of space for humans. 'In a world where animals have more rights to space and food than humans,' said Charlie Leocha, consumer representative on the committee. British Airways has a seat pitch of 31 inches, while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and Virgin Atlantic's is 30-31.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install rouge-score","metadata":{"execution":{"iopub.status.busy":"2024-09-01T20:19:28.348577Z","iopub.execute_input":"2024-09-01T20:19:28.349194Z","iopub.status.idle":"2024-09-01T20:19:44.853507Z","shell.execute_reply.started":"2024-09-01T20:19:28.349155Z","shell.execute_reply":"2024-09-01T20:19:44.852331Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Collecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\nBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=607400ec6180148515277241e78cd42a5c45411928a58e5bd121f84c22776f1b\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge-score\nInstalling collected packages: rouge-score\nSuccessfully installed rouge-score-0.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"from rouge_score import rouge_scorer","metadata":{"execution":{"iopub.status.busy":"2024-09-01T20:19:54.904079Z","iopub.execute_input":"2024-09-01T20:19:54.904486Z","iopub.status.idle":"2024-09-01T20:19:54.957609Z","shell.execute_reply.started":"2024-09-01T20:19:54.904454Z","shell.execute_reply":"2024-09-01T20:19:54.956622Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Assuming `summary` is the generated summary from the previous step\n# and `reference_summary` is the actual summary from the dataset\n\nreference_summary = test_df['highlights'][0]  # Replace with the actual reference summary\ngenerated_summary = summary  # Replace with the summary generated by your model\n\n# Initialize ROUGE scorer\nscorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\nscores = scorer.score(reference_summary, generated_summary)\n\n# Display ROUGE scores\nprint(\"ROUGE-1 (Unigrams):\", scores['rouge1'])\nprint(\"ROUGE-2 (Bigrams):\", scores['rouge2'])\nprint(\"ROUGE-L (Longest Common Subsequence):\", scores['rougeL'])\n","metadata":{"execution":{"iopub.status.busy":"2024-09-01T20:19:57.599894Z","iopub.execute_input":"2024-09-01T20:19:57.600317Z","iopub.status.idle":"2024-09-01T20:19:57.616931Z","shell.execute_reply.started":"2024-09-01T20:19:57.600258Z","shell.execute_reply":"2024-09-01T20:19:57.615716Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"ROUGE-1 (Unigrams): Score(precision=0.13194444444444445, recall=0.5588235294117647, fmeasure=0.21348314606741575)\nROUGE-2 (Bigrams): Score(precision=0.04895104895104895, recall=0.21212121212121213, fmeasure=0.07954545454545454)\nROUGE-L (Longest Common Subsequence): Score(precision=0.06944444444444445, recall=0.29411764705882354, fmeasure=0.11235955056179774)\n","output_type":"stream"}]}]}