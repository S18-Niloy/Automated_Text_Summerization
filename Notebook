{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2734496,"sourceType":"datasetVersion","datasetId":1654566}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.cluster import KMeans\nimport string\nnltk.download('punkt')\nnltk.download('stopwords')","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:45:13.312785Z","iopub.execute_input":"2024-08-31T22:45:13.313157Z","iopub.status.idle":"2024-08-31T22:45:15.656065Z","shell.execute_reply.started":"2024-08-31T22:45:13.313118Z","shell.execute_reply":"2024-08-31T22:45:15.655120Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv')\ntest_df = pd.read_csv('/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv')\nval_df = pd.read_csv('/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/validation.csv')\n\n# Assuming 'article' contains the text and 'highlights' contains the summary\ntrain_texts = train_df['article'].tolist()\ntrain_summaries = train_df['highlights'].tolist()\n\ntest_texts = test_df['article'].tolist()\ntest_summaries = test_df['highlights'].tolist()\n\nval_texts = val_df['article'].tolist()\nval_summaries = val_df['highlights'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:46:04.531578Z","iopub.execute_input":"2024-08-31T22:46:04.531979Z","iopub.status.idle":"2024-08-31T22:46:34.009476Z","shell.execute_reply.started":"2024-08-31T22:46:04.531930Z","shell.execute_reply":"2024-08-31T22:46:34.008343Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def preprocess_text(text):\n    stop_words = set(stopwords.words('english'))\n    text = text.lower()\n    text = ''.join([char for char in text if char not in string.punctuation])\n    words = word_tokenize(text)\n    words = [word for word in words if word not in stop_words]\n    return ' '.join(words)\n\ntrain_texts = [preprocess_text(text) for text in train_texts]\ntest_texts = [preprocess_text(text) for text in test_texts]\nval_texts = [preprocess_text(text) for text in val_texts]","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:46:39.125352Z","iopub.execute_input":"2024-08-31T22:46:39.125804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(max_features=5000)\ntrain_vectors = vectorizer.fit_transform(train_texts)\ntest_vectors = vectorizer.transform(test_texts)\nval_vectors = vectorizer.transform(val_texts)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def summarize_text(text, n_clusters=5):\n    sentences = sent_tokenize(text)\n    vectorizer = TfidfVectorizer(max_features=5000)\n    sentence_vectors = vectorizer.fit_transform(sentences)\n    \n    kmeans = KMeans(n_clusters=n_clusters)\n    kmeans.fit(sentence_vectors)\n    \n    avg = []\n    for j in range(n_clusters):\n        idx = np.where(kmeans.labels_ == j)[0]\n        avg.append(np.mean(idx))\n    \n    summary = ' '.join([sentences[int(i)] for i in np.argsort(avg)])\n    return summary\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example of summarization\nsample_text = test_texts[0]  # Replace with any text from test/validation set\nsummary = summarize_text(sample_text, n_clusters=5)\nprint(summary)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from rouge_score import rouge_scorer\n\ndef evaluate_summary(generated_summary, reference_summary):\n    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n    scores = scorer.score(reference_summary, generated_summary)\n    return scores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example evaluation\nsample_generated_summary = summarize_text(test_texts[0], n_clusters=5)\nsample_reference_summary = test_summaries[0]\n\nscores = evaluate_summary(sample_generated_summary, sample_reference_summary)\nprint(scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}